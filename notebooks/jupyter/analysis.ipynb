{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "results_dir = Path(\"../../results\")\n",
    "dfs = []\n",
    "nrmses = []\n",
    "rmses = []\n",
    "seeds = []\n",
    "datas = []\n",
    "count = []\n",
    "for f in os.listdir(results_dir):\n",
    "    if f.endswith('.csv') is False:\n",
    "        continue\n",
    "    parts = f.split('_')\n",
    "    seed = parts[-2]\n",
    "    data = '_'.join(parts[:-2])\n",
    "    df = pd.read_csv(results_dir / f)\n",
    "    df['seed'] = [seed]*len(df)\n",
    "    df['data'] = [data]*len(df)\n",
    "    df['parts'] = [len(parts[:-2])]*len(df)\n",
    "    count.append(len(parts[:-2]))\n",
    "    dfs.append(df)\n",
    "    rmse = root_mean_squared_error(df['true_labels'], df['predictions'])\n",
    "    rmses.append(rmse)\n",
    "    nrmse = rmse/(np.ptp(df['true_labels']))\n",
    "    nrmses.append(nrmse)\n",
    "    seeds.append(seed)\n",
    "    datas.append(data)\n",
    "all_df = pd.concat(dfs)\n",
    "dem_1part = rmse_df[(rmse_df['data'] == 'dem') & (rmse_df['parts'] == 1)]['nrmse'].mean()\n",
    "dem_2part = rmse_df[(rmse_df['data'] == 'dem_dem') & (rmse_df['parts'] == 2)]['nrmse'].mean()\n",
    "\n",
    "# Calculate percentage improvements for all models\n",
    "p1_improvements = []\n",
    "p1_labels = []\n",
    "p1_lower_errors = []\n",
    "p1_upper_errors = []\n",
    "p2_improvements = []\n",
    "p2_labels = []\n",
    "p2_lower_errors = []\n",
    "p2_upper_errors = []\n",
    "\n",
    "\n",
    "for data_type in rmse_df['data'].unique():\n",
    "    parts = rmse_df[rmse_df['data'] == data_type]['parts'].iloc[0]\n",
    "    nrmse_mean = rmse_df[rmse_df['data'] == data_type]['nrmse'].mean()\n",
    "\n",
    "    # Compare to appropriate baseline\n",
    "    if parts == 1:\n",
    "        baseline = dem_1part\n",
    "        data_rows = rmse_df[rmse_df['data'] == data_type]\n",
    "        pct_improvements = [(baseline - nrmse) / baseline * 100 for nrmse in data_rows['nrmse'].values]\n",
    "        # Error propagation for percentage (approximate)\n",
    "\n",
    "        p1_improvements.append(np.mean(pct_improvements))\n",
    "        p1_lower_errors.append(np.mean(pct_improvements) - np.min(pct_improvements))\n",
    "        p1_upper_errors.append(np.max(pct_improvements) - np.mean(pct_improvements))\n",
    "        p1_labels.append(data_type)\n",
    "    else:\n",
    "        baseline = dem_2part\n",
    "        data_rows = rmse_df[rmse_df['data'] == data_type]\n",
    "        pct_improvements = [(baseline - nrmse) / baseline * 100 for nrmse in data_rows['nrmse'].values]\n",
    "        # Error propagation for percentage (approximate)\n",
    "\n",
    "        p2_improvements.append(np.mean(pct_improvements))\n",
    "        p2_lower_errors.append(np.mean(pct_improvements) - np.min(pct_improvements))\n",
    "        p2_upper_errors.append(np.max(pct_improvements) - np.mean(pct_improvements))\n",
    "        p2_labels.append(data_type)\n",
    "\n",
    "    if data_type == \"dem_dem\":\n",
    "        baseline = dem_1part\n",
    "        data_rows = rmse_df[rmse_df['data'] == data_type]\n",
    "        pct_improvements = [(baseline - nrmse) / baseline * 100 for nrmse in data_rows['nrmse'].values]\n",
    "        # Error propagation for percentage (approximate)\n",
    "\n",
    "        p1_improvements.append(np.mean(pct_improvements))\n",
    "        p1_lower_errors.append(np.mean(pct_improvements) - np.min(pct_improvements))\n",
    "        p1_upper_errors.append(np.max(pct_improvements) - np.mean(pct_improvements))\n",
    "        p1_labels.append(data_type)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "improvement_fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1, ax2 = axs\n",
    "p1_sorted_idx = np.argsort(p1_improvements)\n",
    "p1_improvements = [p1_improvements[i] for i in p1_sorted_idx]\n",
    "p1_lower_errors = [p1_lower_errors[i] for i in p1_sorted_idx]\n",
    "p1_upper_errors = [p1_upper_errors[i] for i in p1_sorted_idx]\n",
    "p1_labels = [p1_labels[i] for i in p1_sorted_idx]\n",
    "\n",
    "ax1.barh(p1_labels, p1_improvements, xerr=[p1_lower_errors, p1_upper_errors], capsize=5)\n",
    "ax1.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "ax1.set_xlabel('% Improvement over Baseline')\n",
    "ax1.set_title('Performance Improvement vs Baseline DEM Model')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "p2_sorted_idx = np.argsort(p2_improvements)\n",
    "p2_improvements = [p2_improvements[i] for i in p2_sorted_idx]\n",
    "p2_lower_errors = [p2_lower_errors[i] for i in p2_sorted_idx]\n",
    "p2_upper_errors = [p2_upper_errors[i] for i in p2_sorted_idx]\n",
    "p2_labels = [p2_labels[i] for i in p2_sorted_idx]\n",
    "\n",
    "ax2.barh(p2_labels, p2_improvements, xerr=[p2_lower_errors, p2_upper_errors], capsize=5)\n",
    "ax2.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "ax2.set_xlabel('% Improvement over Baseline')\n",
    "ax2.set_title('Performance Improvement vs Baseline DEM Model')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "improvement_fig.tight_layout()\n",
    "improvement_fig.show()\n",
    "\n",
    "raw_performance_fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# 1-part models\n",
    "part1_data = all_df[all_df['parts'] == 1]\n",
    "sns.scatterplot(data=part1_data, x='true_labels', y='predictions',\n",
    "                hue='data', style='seed', alpha=0.5, s=20, ax=axs[0])\n",
    "\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('True D/K (log scale)')\n",
    "axs[0].set_ylabel('Predicted D/K (log scale)')\n",
    "axs[0].set_title('1-Part Model Predictions')\n",
    "axs[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axs[0].grid(alpha=0.3)\n",
    "# Add 1:1 line\n",
    "min_val = min(part1_data['true_labels'].min(), part1_data['predictions'].min())\n",
    "max_val = max(part1_data['true_labels'].max(), part1_data['predictions'].max())\n",
    "axs[0].plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='1:1 line')#, zorder=0)\n",
    "# histogram of data in background\n",
    "ax02 = axs[0].twinx()\n",
    "ax02.hist(part1_data['true_labels'], bins=50, color='gray', alpha=0.3)\n",
    "\n",
    "# 2-part models\n",
    "part2_data = all_df[all_df['parts'] == 2]\n",
    "sns.scatterplot(data=part2_data, x='true_labels', y='predictions',\n",
    "                hue='data', style='seed', alpha=0.5, s=20, ax=axs[1])\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('True D/K (log scale)')\n",
    "axs[1].set_ylabel('Predicted D/K (log scale)')\n",
    "axs[1].set_title('2-Part Model Predictions')\n",
    "axs[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axs[1].grid(alpha=0.3)\n",
    "# Add 1:1 line\n",
    "min_val = min(part2_data['true_labels'].min(), part2_data['predictions'].min())\n",
    "max_val = max(part2_data['true_labels'].max(), part2_data['predictions'].max())\n",
    "axs[1].plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=2, label='1:1 line')#, zorder=0)\n",
    "ax12 = axs[1].twinx()\n",
    "ax12.hist(part2_data['true_labels'], bins=50, color='gray', alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "raw_performance_fig.tight_layout()\n",
    "raw_performance_fig.show()\n",
    "\n",
    "def moving_window_nrmse(y_true, y_pred, window_frac=0.2):\n",
    "    \"\"\"Calculate NRMSE in a moving window along sorted true values\"\"\"\n",
    "    sorted_idx = np.argsort(y_true)\n",
    "    y_true_sorted = y_true[sorted_idx]\n",
    "    y_pred_sorted = y_pred[sorted_idx]\n",
    "\n",
    "    window_size = int(len(y_true) * window_frac)\n",
    "    nrmses = []\n",
    "    centers = []\n",
    "\n",
    "    for i in range(len(y_true) - window_size):\n",
    "        window_true = y_true_sorted[i:i+window_size]\n",
    "        window_pred = y_pred_sorted[i:i+window_size]\n",
    "\n",
    "        rmse = root_mean_squared_error(window_true, window_pred)#np.sqrt(np.mean((window_true - window_pred)**2))\n",
    "        nrmse = rmse / np.ptp(window_true)\n",
    "\n",
    "        nrmses.append(nrmse)\n",
    "        centers.append(np.mean(window_true))\n",
    "\n",
    "    return np.array(centers), np.array(nrmses)\n",
    "\n",
    "window_nrmse_fig, (ax5, ax6) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "one_part_data = all_df[all_df['parts'] == 1]\n",
    "for data_type in sorted(one_part_data['data'].unique()):\n",
    "    data_subset = all_df[all_df['data'] == data_type]\n",
    "\n",
    "    # Calculate for each seed and average\n",
    "    all_centers = []\n",
    "    all_nrmses = []\n",
    "\n",
    "    for seed in data_subset['seed'].unique():\n",
    "        seed_data = data_subset[data_subset['seed'] == seed]\n",
    "        centers, nrmses = moving_window_nrmse(\n",
    "            seed_data['true_labels'].values,\n",
    "            seed_data['predictions'].values,\n",
    "            window_frac=0.1\n",
    "        )\n",
    "        all_centers.append(centers)\n",
    "        all_nrmses.append(nrmses)\n",
    "\n",
    "    # Average across seeds (they should have same length if same dataset)\n",
    "    if len(all_nrmses) > 0:\n",
    "        mean_nrmse = np.mean(all_nrmses, axis=0)\n",
    "        mean_centers = np.mean(all_centers, axis=0)\n",
    "\n",
    "        ax5.plot(mean_centers, mean_nrmse, linewidth=2, label=data_type)\n",
    "\n",
    "ax5.set_xlabel('True D/K Value')\n",
    "ax5.set_ylabel('Local NRMSE')\n",
    "ax5.set_title('Rolling NRMSE: 1-Part Models')\n",
    "ax5.legend()\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# 2-part models rolling NRMSE\n",
    "two_part_data = all_df[all_df['parts'] == 2]\n",
    "for data_type in sorted(two_part_data['data'].unique()):\n",
    "    data_subset = all_df[all_df['data'] == data_type]\n",
    "\n",
    "    # Calculate for each seed and average\n",
    "    all_centers = []\n",
    "    all_nrmses = []\n",
    "\n",
    "    for seed in data_subset['seed'].unique():\n",
    "        seed_data = data_subset[data_subset['seed'] == seed]\n",
    "        centers, nrmses = moving_window_nrmse(\n",
    "            seed_data['true_labels'].values,\n",
    "            seed_data['predictions'].values,\n",
    "            window_frac=0.1\n",
    "        )\n",
    "        all_centers.append(centers)\n",
    "        all_nrmses.append(nrmses)\n",
    "\n",
    "    # Average across seeds\n",
    "    if len(all_nrmses) > 0:\n",
    "        mean_nrmse = np.mean(all_nrmses, axis=0)\n",
    "        mean_centers = np.mean(all_centers, axis=0)\n",
    "\n",
    "        ax6.plot(mean_centers, mean_nrmse, linewidth=2, label=data_type)\n",
    "\n",
    "ax6.set_xlabel('True D/K Value')\n",
    "ax6.set_ylabel('Local NRMSE')\n",
    "ax6.set_title('Rolling NRMSE: 2-Part Models')\n",
    "ax6.legend()\n",
    "ax6.grid(alpha=0.3)\n",
    "ax5.set_xscale('log')\n",
    "ax6.set_xscale('log')\n",
    "\n",
    "window_nrmse_fig.tight_layout()\n",
    "window_nrmse_fig.show()\n",
    "\n",
    "improvement_fig.savefig(\"../../results/figures/improvement_over_baseline.png\", dpi=300)\n",
    "raw_performance_fig.savefig(\"../../results/figures/raw_performance_scatter.png\", dpi=300)\n",
    "window_nrmse_fig.savefig(\"../../results/figures/rolling_nrmse.png\", dpi=300)\n",
    "\n",
    "\n",
    "```"
   ],
   "id": "a744b0fe-53f8-43cf-ad83-8fd70cb7ce4e"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
